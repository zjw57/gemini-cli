name: 'Eval'

on:
  workflow_dispatch:
    inputs:
      branch-or-commit:
        description: 'The branch or commit to run the evaluation on.'
        required: true
        type: 'string'
      dry-run:
        description: 'dry run: runs evaluation without creating an issue.'
        required: false
        type: 'boolean'
        default: true


defaults:
  run:
    shell: 'bash'

permissions:
  contents: 'read'
  id-token: 'write'
  packages: 'read'
  issues: 'write'

jobs:
  eval:
    name: 'Eval'
    if: >-
      github.repository == 'google-gemini/gemini-cli'
    runs-on: 'ubuntu-latest'
    container:
      image: 'ghcr.io/google-gemini/gemini-cli-swe-agent-eval@sha256:cd5edc4afd2245c1f575e791c0859b3c084a86bb3bd9a6762296da5162b35a8f'
      credentials:
        username: '${{ github.actor }}'
        password: '${{ secrets.GITHUB_TOKEN }}'
      env:
        GITHUB_TOKEN: '${{ secrets.GITHUB_TOKEN }}'
        DEFAULT_VERTEXAI_PROJECT: '${{ vars.GOOGLE_CLOUD_PROJECT }}'
        GOOGLE_CLOUD_PROJECT: '${{ vars.GOOGLE_CLOUD_PROJECT }}'
        GEMINI_API_KEY: '${{ secrets.EVAL_GEMINI_API_KEY }}'
        GCLI_LOCAL_FILE_TELEMETRY: 'True'
        EVAL_GCS_BUCKET: '${{ vars.EVAL_GCS_ARTIFACTS_BUCKET }}'
    steps:
      - name: 'Checkout repository'
        uses: 'actions/checkout@v4' # ratchet:exclude
        with:
          ref: ${{ inputs.branch-or-commit }}

      - name: 'Authenticate to Google Cloud'
        id: 'auth'
        uses: 'google-github-actions/auth@v2' # ratchet:exclude
        with:
          project_id: '${{ vars.GOOGLE_CLOUD_PROJECT }}'
          workload_identity_provider: '${{ vars.GCP_WIF_PROVIDER }}'
          service_account: '${{ vars.SERVICE_ACCOUNT_EMAIL }}'
          token_format: 'access_token'
          access_token_scopes: 'https://www.googleapis.com/auth/cloud-platform'

      - name: 'Run evaluation'
        working-directory: '/app'
        run: |
          poetry run exp_run --experiment-mode=on-demand --branch-or-commit=${{ inputs.branch-or-commit }} --model-name=gemini-2.5-pro --dataset=swebench_verified --concurrency=15
          poetry run python agent_prototypes/scripts/parse_gcli_logs_experiment.py --experiment_dir=experiments/adhoc/gcli_temp_exp --gcs-bucket="${EVAL_GCS_BUCKET}" --gcs-path=gh_action_artifacts

      - name: 'Get evaluation summary'
        id: 'calculate-rates'
        working-directory: '/app'
        run: |
          poetry run bash $GITHUB_WORKSPACE/scripts/calculate_eval_success_rates.sh /app/experiments/adhoc/gcli_temp_exp/artifacts/summary_stats.md

      - name: 'Check evaluation threshold'
        if: >-
          ${{(steps.calculate-rates.outputs.resolution-rate <= 90 ||
          steps.calculate-rates.outputs.tool-success-rate <= 80) }}
        uses: 'actions/github-script@v7' # ratchet:exclude
        with:
          script: |
            const resolutionRate = ${{ steps.calculate-rates.outputs.resolution-rate }};
            const toolSuccessRate = ${{ steps.calculate-rates.outputs.tool-success-rate }};
            const branchOrCommit = '${{ inputs.branch-or-commit }}';
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const dryRun = ${{ inputs.dry-run }};

            const title = `⚠️ Evaluation below threshold for ${branchOrCommit}`;
            const body = `
            Evaluation for \`${branchOrCommit}\` failed to meet the required thresholds.

            - **Resolution Rate**: ${resolutionRate}% (Threshold: 90%)
            - **Tool Success Rate**: ${toolSuccessRate}% (Threshold: 80%)

            [View Workflow Run](${runUrl})
            `;

            if (dryRun) {
              console.log('Dry run enabled. Would create issue with:');
              console.log(`Title: ${title}`);
              console.log(`Body: ${body}`);
            } else {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['eval-failure']
              });
            }